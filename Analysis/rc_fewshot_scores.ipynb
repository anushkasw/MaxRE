{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def f1_score(true, pred_result):\n",
    "    correct = 0\n",
    "    total = len(true)\n",
    "    correct_positive = 0\n",
    "    pred_positive = 0\n",
    "    gold_positive = 0\n",
    "\n",
    "    for i in range(total):\n",
    "        golden = true[i]\n",
    "        if golden == pred_result[i]:\n",
    "            correct += 1\n",
    "            if golden not in ['NA', 'na', 'no_relation', 'Other', 'Others', 'false', 'unanswerable', 'NONE']:\n",
    "                correct_positive += 1\n",
    "        if golden not in ['NA', 'na', 'no_relation', 'Other', 'Others', 'false', 'unanswerable', 'NONE']:\n",
    "            gold_positive +=1\n",
    "        if pred_result[i] not in ['NA', 'na', 'no_relation', 'Other', 'Others', 'false', 'unanswerable', 'NONE']:\n",
    "            pred_positive += 1\n",
    "    acc = float(correct) / float(total)\n",
    "    try:\n",
    "        micro_p = float(correct_positive) / float(pred_positive)\n",
    "    except:\n",
    "        micro_p = 0\n",
    "    try:\n",
    "        micro_r = float(correct_positive) / float(gold_positive)\n",
    "    except:\n",
    "        micro_r = 0\n",
    "    try:\n",
    "        micro_f1 = 2 * micro_p * micro_r / (micro_p + micro_r)\n",
    "    except:\n",
    "        micro_f1 = 0\n",
    "    result = {'acc': acc, 'micro_p': micro_p, 'micro_r': micro_r, 'micro_f1': micro_f1}\n",
    "    return result"
   ],
   "id": "4e527fd06b2f8de5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def f1_score_na(true, pred_result):\n",
    "    correct = 0\n",
    "    total = len(true)\n",
    "    correct_positive = 0\n",
    "    pred_positive = 0\n",
    "    gold_positive = 0\n",
    "\n",
    "    for i in range(total):\n",
    "        golden = true[i]\n",
    "        if golden == pred_result[i]:\n",
    "            correct += 1\n",
    "            correct_positive += 1\n",
    "        gold_positive +=1\n",
    "        pred_positive += 1\n",
    "    acc = float(correct) / float(total)\n",
    "    try:\n",
    "        micro_p = float(correct_positive) / float(pred_positive)\n",
    "    except:\n",
    "        micro_p = 0\n",
    "    try:\n",
    "        micro_r = float(correct_positive) / float(gold_positive)\n",
    "    except:\n",
    "        micro_r = 0\n",
    "    try:\n",
    "        micro_f1 = 2 * micro_p * micro_r / (micro_p + micro_r)\n",
    "    except:\n",
    "        micro_f1 = 0\n",
    "    result = {'acc': acc, 'micro_p': micro_p, 'micro_r': micro_r, 'micro_f1': micro_f1}\n",
    "    return result"
   ],
   "id": "decdb01f410256cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "methods = ['KnowPrompt', '020', 'Roberta_base', 'GenPT/Bart', 'GenPT/T5', 'GenPT/roberta', 'GPT-RE', 'DeepKE']",
   "id": "f446a06fa73de8e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = ['crossRE', 'NYT10', 'FewRel', 'tacred', 'retacred', 'WebNLG', 'semeval_nodir']",
   "id": "2e78ba24766b430b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(columns=['Method','Dataset','k', 'f1','p','r'])\n",
    "for method in methods:\n",
    "    print(method)\n",
    "    if method.split('/')[0]=='GenPT':\n",
    "        name = 'GenPT'\n",
    "    else:\n",
    "        name = method\n",
    "        \n",
    "    for data in dataset:\n",
    "        for k in [1, 5,10,20,30]:\n",
    "            f1 = []\n",
    "            p = []\n",
    "            r = []\n",
    "            for seed in [13, 42, 100]:\n",
    "                try:\n",
    "                    res_file = f'{base_path}/{method}/few_output/{data}/{seed}-{k}/{name}_test.jsonl'\n",
    "                    with open(res_file) as f:\n",
    "                        batch = f.read().splitlines()\n",
    "                    batch = [json.loads(line) for line in batch if line != '']\n",
    "\n",
    "                    true_label = [x['label_true'] for x in batch]\n",
    "                    pred_label = [x['label_pred'] for x in batch]\n",
    "\n",
    "                    results = f1_score(true_label, pred_label)\n",
    "\n",
    "                    f1.append(results['micro_f1'])\n",
    "                    p.append(results['micro_p'])\n",
    "                    r.append(results['micro_r'])\n",
    "                except:\n",
    "                    # print(f'Missing {data}, {k}, {seed}')\n",
    "                    continue\n",
    "\n",
    "            new_row = {\n",
    "                'Method': method,\n",
    "                'Dataset': data,\n",
    "                'k': k,\n",
    "                'f1': np.mean(f1),\n",
    "                'p': np.mean(p),\n",
    "                'r': np.mean(r)\n",
    "            }\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "    print('\\n')\n",
    "        \n",
    "    "
   ],
   "id": "30b882fc57584fe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "g_df = df.groupby(['Method', 'Dataset', 'k'], as_index=False).mean()",
   "id": "f9338a71d65c6559"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "g_df['Method'] = g_df.apply(lambda x: 'RBERT' if x['Method']=='020' else 'UnleashLLM'\n",
    "                            if x['Method']=='DeepKE' else x['Method'], axis=1)"
   ],
   "id": "e8b377542456ac40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the k values and methods\n",
    "k_values = [1, 5, 10, 20, 30]\n",
    "methods = g_df['Method'].unique()\n",
    "\n",
    "# Create a new DataFrame for the multi-level index (Method, k_value)\n",
    "g_df['k_str'] = 'k=' + g_df['k'].astype(str)  # Create string versions of the k values for labeling\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x=g_df['Method'] + ' ' + g_df['k_str'], y='f1', data=g_df, palette='Set3',\n",
    "            boxprops={'facecolor': 'none', 'edgecolor': 'black'},  # Transparent box with black edges\n",
    "            whiskerprops={'color': 'black'},\n",
    "            capprops={'color': 'black'},\n",
    "            medianprops={'color': 'black'}, ax=ax)\n",
    "\n",
    "# Overlay stripplot to show individual data points with different colors\n",
    "sns.stripplot(x=g_df['Method'] + ' ' + g_df['k_str'], y='f1', hue='Dataset', data=g_df, dodge=False, palette='bright',\n",
    "              marker='o', alpha=0.7, size=8, ax=ax)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_ylabel('F1 Score', fontsize=14)\n",
    "# ax.set_xlabel('Methods', fontsize=14)\n",
    "\n",
    "# Increase fontsize of x and y ticks\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Get the current axis\n",
    "ax.set_xticklabels([])  # Remove the current x-axis labels\n",
    "\n",
    "# Define primary x-axis ticks (for methods + k values)\n",
    "primary_xtick_positions = np.arange(len(methods) * len(k_values))  # Assumes each method has all k_values\n",
    "ax.set_xticks(primary_xtick_positions)\n",
    "\n",
    "# Get combined labels for methods + k values (display only k values)\n",
    "method_k_labels = [f\"{k}\" for method in methods for k in k_values]\n",
    "ax.set_xticklabels(method_k_labels, rotation=0, ha='right', fontsize=12)\n",
    "\n",
    "# Secondary x-axis for grouping by methods (instead of k-values)\n",
    "sec = ax.secondary_xaxis(location=0)\n",
    "\n",
    "# Generate the method labels with one label per group, the rest will be empty\n",
    "method_labels = []\n",
    "for method in methods:\n",
    "    method_labels.extend(['', '', method, '', ''])\n",
    "\n",
    "# Set the secondary x-axis labels\n",
    "sec.set_xticks(np.arange(len(method_labels)), labels=[f'\\n\\n{label}' for label in method_labels], fontsize=14)\n",
    "\n",
    "# Secondary x-axis to visually separate the groups of methods\n",
    "sec2 = ax.secondary_xaxis(location=0)\n",
    "sec2.set_xticks(np.linspace(-0.5, len(method_k_labels)-0.5, len(methods)+1), labels=[])\n",
    "sec2.tick_params('x', length=40, width=1.5)\n",
    "\n",
    "# Add the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "custom_hue_labels = ['FewRel', 'NYT10', 'WebNLG', 'CrossRE', 'RETACRED', 'SemEval', 'TACRED']  # Replace with your custom hue labels\n",
    "\n",
    "plt.legend(handles, custom_hue_labels, title='Datasets', loc='upper center', fontsize=14, title_fontsize=14,\n",
    "           bbox_to_anchor=(0.5, 1.2), ncol=len(custom_hue_labels), frameon=False)\n",
    "\n",
    "# Adjust layout for a better fit\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the entire figure as a PNG file\n",
    "plt.savefig('./images/few_all_subplots.png', format='png', dpi=600, bbox_inches='tight')  # Save with 600 DPI\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "id": "b70268e308b7e7a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c2612ceaa7c2f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8067701005f0ff59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
